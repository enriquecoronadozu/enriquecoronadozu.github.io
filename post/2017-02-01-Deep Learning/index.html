<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="theme" content="hugo-academic">
  <meta name="generator" content="Hugo 0.18.1" />
  <meta name="author" content="Enrique Coronado">
  <meta name="description" content="PhD student">

  
  
  
    
  
  
    
    
    <link rel="stylesheet" href="/css/highlight.min.css">
    
  
  <link rel="stylesheet" href="/css/bootstrap.min.css">
  <link rel="stylesheet" href="/css/font-awesome.min.css">
  <link rel="stylesheet" href="/css/academicons.min.css">
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato:400,700|Merriweather|Roboto+Mono">
  <link rel="stylesheet" href="/css/hugo-academic.css">
  

  <link rel="alternate" href="https://enriquecoronadozu.github.io/index.xml" type="application/rss+xml" title="">
  <link rel="feed" href="https://enriquecoronadozu.github.io/index.xml" type="application/rss+xml" title="">

  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/apple-touch-icon.png">

  <link rel="canonical" href="https://enriquecoronadozu.github.io/post/2017-02-01-Deep%20Learning/">

  

  <title>Deep Learning: Introduction to Recurrent Neural Networks | </title>

</head>
<body id="top" data-spy="scroll" data-target="#navbar-main" data-offset="71">

<nav class="navbar navbar-default navbar-fixed-top" id="navbar-main">
  <div class="container">

    
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse"
              data-target=".navbar-collapse" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="/"></a>
    </div>

    
    <div class="collapse navbar-collapse">

      
      <ul class="nav navbar-nav navbar-right">
        

        

        <li class="nav-item">
          <a href="/#about">
            
            <span>Home</span>
          </a>
        </li>

        
        

        

        <li class="nav-item">
          <a href="/#publications">
            
            <span>Publications</span>
          </a>
        </li>

        
        

        

        <li class="nav-item">
          <a href="/#posts">
            
            <span>Posts</span>
          </a>
        </li>

        
        

        

        <li class="nav-item">
          <a href="/#projects">
            
            <span>Projects</span>
          </a>
        </li>

        
        

        

        <li class="nav-item">
          <a href="/#teaching">
            
            <span>Teaching</span>
          </a>
        </li>

        
        

        

        <li class="nav-item">
          <a href="/#contact">
            
            <span>Contact</span>
          </a>
        </li>

        
        
      </ul>

    </div>
  </div>
</nav>


<article class="article" itemscope itemtype="http://schema.org/Article">

  

  <div class="article-container">
    <h1 itemprop="name">Deep Learning: Introduction to Recurrent Neural Networks</h1>
    

<div class="article-metadata">

  <span class="article-date">
    <time datetime="2017-02-01 10:00:00 &#43;0000 UTC" itemprop="datePublished">
      Wed, Feb 1, 2017
    </time>
  </span>

  

  
  
  
  <span class="article-tags">
    <i class="fa fa-tags"></i>
    
    <a href="/tags/deep-learning">deep learning</a
    >
    
  </span>
  
  

  
  
<div class="share-box" aria-hidden="true">
  <ul class="share">
    <li>
      <a class="facebook"
         href="https://www.facebook.com/sharer.php?u=https%3a%2f%2fenriquecoronadozu.github.io%2fpost%2f2017-02-01-Deep%2520Learning%2f"
         target="_blank">
        <i class="fa fa-facebook"></i>
      </a>
    </li>
    <li>
      <a class="twitter"
         href="https://twitter.com/intent/tweet?text=Deep%20Learning%3a%20Introduction%20to%20Recurrent%20Neural%20Networks&amp;url=https%3a%2f%2fenriquecoronadozu.github.io%2fpost%2f2017-02-01-Deep%2520Learning%2f"
         target="_blank">
        <i class="fa fa-twitter"></i>
      </a>
    </li>
    <li>
      <a class="linkedin"
         href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fenriquecoronadozu.github.io%2fpost%2f2017-02-01-Deep%2520Learning%2f&amp;title=Deep%20Learning%3a%20Introduction%20to%20Recurrent%20Neural%20Networks"
         target="_blank">
        <i class="fa fa-linkedin"></i>
      </a>
    </li>
    <li>
      <a class="weibo"
         href="http://service.weibo.com/share/share.php?url=https%3a%2f%2fenriquecoronadozu.github.io%2fpost%2f2017-02-01-Deep%2520Learning%2f&amp;title=Deep%20Learning%3a%20Introduction%20to%20Recurrent%20Neural%20Networks"
         target="_blank">
        <i class="fa fa-weibo"></i>
      </a>
    </li>
    <li>
      <a class="email"
         href="mailto:?subject=Deep%20Learning%3a%20Introduction%20to%20Recurrent%20Neural%20Networks&amp;body=https%3a%2f%2fenriquecoronadozu.github.io%2fpost%2f2017-02-01-Deep%2520Learning%2f">
        <i class="fa fa-envelope"></i>
      </a>
    </li>
  </ul>
</div>


  

</div>

    <div class="article-style" itemprop="articleBody">
      <p>This post gives and introduction to Recurrent Neural Networks (RNN) </p>

<h2 id="notations">Notations:</h2>

<h3 id="list-of-abbrevations">List of abbrevations</h3>

<ul>
<li>RNN (Recurrent Neural Networks)</li>
<li>FFN (Feed-forward network)</li>
</ul>

<h3 id="list-of-symbols">List of symbols</h3>

<ul>
<li>$T$,  length of a sequence</li>
<li>$\tau$ length of a minibatch of a sequence</li>
<li>$\mathbf{x} = {x_1, x_2, \dots, x_n }$, vector set</li>
<li>$\mathcal{X} = {x_1, x_2, \dots, x_T }$,  sequence</li>
<li>$x$,  element of a set or of a sequence</li>
<li>$\mathbf{h}$ state in the hidden units of the network</li>
<li>$t$,    time step</li>
</ul>

<h2 id="theory">Theory:</h2>

<h3 id="recurrent-neural-networks-rnn">Recurrent Neural Networks (RNN)</h3>

<p>Type of Neural Network for processing <strong>secuential data</strong>.</p>

<p>Main ideas:</p>

<ul>
<li>Are called recurrent becuase perform the same task for every element of a sequence</li>
<li>Have a memory that capture the information calculated before</li>
<li>Use cycles to represent the influnce of past values at the current value</li>
</ul>

<h3 id="comparison-between-traditional-neural-networks-and-rnn">Comparison between traditional Neural Networks and RNN</h3>

<p>Traditional Neural Networks:</p>

<ul>
<li>Outputs are independent of previous computations (no good idea for prediction)</li>
<li>Inputs are <strong>sets</strong> of features of fixed length</li>
<li>Diferent parameters (weights) for each input feature</li>
</ul>

<p>Recurrent Neural Networks:</p>

<ul>
<li>Outputs are dependents of previous computations (each output is a function of the previous outputs)</li>
<li>Inputs are <strong>sequential</strong> information (can be of variable length)</li>
<li>Parameter sharing: share the same weights across several time steps. This make possible to apply a RNN model to examples of diferent lengths.</li>
</ul>

<p><em>Note: See appendix A to know more about sequences</em></p>

<h3 id="feed-forward-network-ffn">Feed-forward network (FFN)</h3>

<p>Given a vector set $\mathbf{x} = {x_1, x_2, \dots , x_j, \dots, x_n }$ of $n$ inputs features, the output $i$ of a FFN is given by:</p>

<p>\begin{equation}
y<em>i = f \left( \sum</em>{j}^{m} W_{ij}  x_j + b_i \right)
\end{equation}</p>

<p>Which represent the sum of each element $j$ of the vector of inputs multiplied by the weigth $(i,j)$ in the neuron $i$ plus the bias value in the neuron $i$, and $f$ represent the output function (also called activation function).</p>

<p>Its matrix form is represeted as:</p>

<p>\begin{equation}
\mathbf{y} = \mathbf{W} \mathbf{x} + \mathbf{b}
\end{equation}</p>

<p>where $\mathbf{y}= { y_1, y_2, \dots, y_m }$ is the vector of outputs,  $\mathbf{W}$ a the matrix of weights, and $\mathbf{b} = { b_1, b_2, \dots, b_m }$ is a vector of bias.</p>

<h3 id="rnn-operation">RNN operation:</h3>

<p>Given a sequence $X = {x_1, x_2, \dots, x_T }$, a new state $\mathbf{h}$ in the hidden units of the RNN is given by the next recurrent function:</p>

<p>\begin{equation}
\mathbf{h}_t = f<em>h\left(\mathbf{W}\mathbf{h}</em>{t-1} + \mathbf{U}\mathbf{x}_{t} + \mathbf{b}_h \right)
\end{equation}</p>

<p>The output $\mathbf{y}_t$ is computed as:</p>

<p>\begin{equation}
\mathbf{y}_t = f_y \left(  \mathbf{V} \mathbf{h}_t + \mathbf{b}_y  \right)
\end{equation}</p>

<p>Where $\mathbf{W}$, $\mathbf{U}$ and $\mathbf{V}$ are matrices of parameters. Also $\mathbf{b}_h$ and $\mathbf{b}_h$ are vectors of bias values and $f_h$ and $f_y$ are activation functions.</p>

<ul>
<li>RNN operates in mini batches of the $X$ sequence. Each minibatch can have diferent sequence length $\tau$.</li>
</ul>

<h3 id="references">References:</h3>

<p>Goodfellow, I., Bengio, Y., &amp; Courville, A. (2016). Deep learning. MIT Press.</p>

<h2 id="example-1-simple-keras-implementation">Example 1: Simple Keras implementation</h2>

<p>In this example the well known pima dataset (<a href="https://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes" target="_blank">https://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes</a>) will be used as example of a clasification task using RNN</p>

<h3 id="step-1-import-python-libraries-and-load-data-set">Step 1: Import python libraries and load data set</h3>

<pre><code class="language-python"># Import libraries
from numpy import*
from keras.models import Sequential
from keras.layers import Dense, SimpleRNN, Embedding, Activation, LSTM

# load pima indians dataset
dataset = loadtxt(&quot;pima-indians-diabetes.csv&quot;, delimiter=&quot;,&quot;)
# split into input (X) and output (Y) variables
X = dataset[:500,0:8]
Y = dataset[:500,8]

# For validation
X_val = dataset[500:600,0:8]
Y_val = dataset[500:600,8]

n_example,n_inputs = shape(X)
</code></pre>

<h3 id="step-2-create-a-new-sequential-model">Step 2: Create a new sequential model</h3>

<p>We need to define:
- The firts layer
- The other hidden layers if needed
- The output layer</p>

<p>The model needs to know what input shape it should expect. For this reason, the first layer in a Sequential model (and only the first) needs to receive information about its input shape.</p>

<pre><code class="language-python"># Step 2.1: Specification of a sequential model
model = Sequential()
# Step 2.2: Defintion of the first layer
#model.add(SimpleRNN(32, input_shape=(1,8)))
#model.add(Activation(&quot;sigmoid&quot;))
# Step 2.3 Definition of the uutput layer
# model.add(Dense(10, 1, activation = &quot;sigmoid&quot;))
#model.add(Dense(5))

# Firts layer
#model.add(Embedding(n_inputs, 500))
#model.add(SimpleRNN(3, input_dim = n_inputs))
#model.add(LSTM(3, input_dim = n_inputs))

#model.add(Masking(0, input_dim = n_inputs))
model.add(SimpleRNN(3, input_dim = n_inputs))

#Final
model.add(Dense(1, activation = &quot;sigmoid&quot;))



</code></pre>

<h3 id="step-3-compile-the-model">Step 3: Compile the model</h3>

<p>This can be done using the next function</p>

<pre><code class="language-python">model.compile(loss='binary_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

#model.compile(loss='mean_squared_error',
#              optimizer='adam',
#              metrics=['accuracy'])
</code></pre>

<h3 id="step-4-reshape-the-data">Step 4: reshape the data</h3>

<pre><code class="language-python">trainX = reshape(X, (X.shape[0],1,X.shape[1]))
validateX = reshape(X_val, (X_val.shape[0],1,X_val.shape[1]))
</code></pre>

<h3 id="step-5-fit-the-data">Step 5: Fit the data</h3>

<pre><code class="language-python">
print('Training ...')
model.fit(trainX,Y, batch_size=10, nb_epoch=150, verbose=0)
print ('Training complete')
</code></pre>

<pre><code>Training ...
Training complete
</code></pre>

<h3 id="step-5-evaluate-the-network">Step 5: Evaluate the network</h3>

<pre><code class="language-python">scores = model.evaluate(validateX, Y_val)
print(model.metrics_names[1], scores[1]*100)
</code></pre>

<pre><code> 32/100 [========&gt;.....................] - ETA: 0s('acc', 68.0)
</code></pre>

<h3 id="references-1">References:</h3>

<p><a href="https://keras.io/getting-started/sequential-model-guide/#specifying-the-input-shape" target="_blank">https://keras.io/getting-started/sequential-model-guide/#specifying-the-input-shape</a></p>

<h2 id="appendix">Appendix</h2>

<h3 id="a-what-is-a-sequence">A:  What is a sequence?</h3>

<ul>
<li>A sequence is an enumerated collection of objects (i.e list of elements that are in some order).</li>
<li>The number of elements is called the length of the sequence, is represented in this tutorial as $T$</li>
<li>The same elements can appear multiple times at different positions in the sequence.</li>
<li>Unlike a set, order matters.</li>
</ul>

<p>Reference from: <a href="https://en.wikipedia.org/wiki/Sequence" target="_blank">https://en.wikipedia.org/wiki/Sequence</a></p>

<p><strong>Additional theory:</strong></p>

<ul>
<li>Sets: <a href="https://en.wikipedia.org/wiki/Set_(mathematics" target="_blank">https://en.wikipedia.org/wiki/Set_(mathematics</a>)</li>
<li>Basic explanation of sets and sequences: <a href="http://www.mathsisfun.com/algebra/sequences-series.html" target="_blank">http://www.mathsisfun.com/algebra/sequences-series.html</a></li>
</ul>
    </div>
  </div>

</article>

<div class="container">
  <nav>
  <ul class="pager">
    
    <li class="previous"><a href="https://enriquecoronadozu.github.io/post/2017-02-02-Useful%20links%20for%20Github%20pages/"><span
      aria-hidden="true">&larr;</span> Useful links for Github pages</a></li>
    

    
    <li class="next"><a href="https://enriquecoronadozu.github.io/post/2017-02-03-ZeroQM%20basics/">ZeroMQ basics <span
      aria-hidden="true">&rarr;</span></a></li>
    
  </ul>
</nav>

</div>

<div class="article-container">
  

</div>

<footer class="site-footer">
  <div class="container">
    <p class="powered-by">

      &copy; 2017 Enrique Coronado &middot; 

      Powered by the <a href="https://github.com/gcushen/hugo-academic" target="_blank">Academic
      theme</a> for <a href="http://gohugo.io" target="_blank">Hugo</a>.

      <span class="pull-right" aria-hidden="true">
        <a href="#" id="back_to_top">
          <span class="button_icon">
            <i class="fa fa-chevron-up fa-2x"></i>
          </span>
        </a>
      </span>

    </p>
  </div>
</footer>

    <script src="//cdnjs.cloudflare.com/ajax/libs/gsap/1.18.4/TweenMax.min.js"></script>
    <script src="//cdnjs.cloudflare.com/ajax/libs/gsap/latest/plugins/ScrollToPlugin.min.js"></script>
    <script src="/js/jquery-1.12.3.min.js"></script>
    <script src="/js/bootstrap.min.js"></script>
    <script src="/js/isotope.pkgd.min.js"></script>
    <script src="//cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.1/imagesloaded.pkgd.min.js"></script>
    <script src="/js/hugo-academic.js"></script>
    

    

    
    
      
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.9.0/highlight.min.js"></script>

      

      

      <script>hljs.initHighlightingOnLoad();</script>
    

    
    
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });
    </script>
    <script async src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML"></script>
    

  </body>
</html>

